# NLP Learning: Text Preprocessing

# For more in Detail Refer:https://chatgpt.com/canvas/shared/67af9af4b3b88191b85dc38d27763a3f



## Introduction  
Before a model can understand text, it must be cleaned and structured. **Text Preprocessing** is an essential step that improves accuracy and performance.  

## Topics Covered  

### 1. Tokenization  
- Splitting text into words/sentences  
- Implemented using **NLTK** and **spaCy**  

### 2. Stopwords Removal  
- Removing common words (e.g., "is", "the", "and")  
- Helps models focus on important words  

### 3. Stemming vs. Lemmatization  
- **Stemming:** Reduces words to their root form (e.g., "running" → "run")  
- **Lemmatization:** Converts words to their base form (e.g., "better" → "good")  

## Why is This Important?  
- Raw text contains **noise** (extra characters, irrelevant words).  
- Preprocessing ensures **clean input** for better model accuracy.  


## How to Run  
1. Clone the repository  
   ```bash
   git clone https://github.com/mudavathkalyan/GEN_AI.git

